{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa72dc9d",
   "metadata": {},
   "source": [
    "# Ler o arquivo CSV e criar um Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1bcccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.csv(\"dbfs:/Volumes/workspace/default/arquivos-aula/arquivos_csv/Clientes.csv\", header=\"True\", inferSchema=\"True\") # Informa o tipo de dados que contém no arquivo CSV, exemplo: int, string, double e etc.\n",
    "\n",
    "# Apenas mostra o Data Frame (os dados)\n",
    "display(spark.read.csv(\"dbfs:/Volumes/workspace/default/arquivos-aula/arquivos_csv/Clientes.csv\", header=\"True\", inferSchema=\"True\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a2684",
   "metadata": {},
   "source": [
    "# Header = True = Indica que a primeira linha do arquivo é o cabeçalho\n",
    "# InferSchema = Indica que o Spark vai inferir o tipo de dados que contém no arquivo CSV, exemplo: int, string, double e etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781ece6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho do arquivo\n",
    "file_path = 'dbfs:/Volumes/workspace/default/arquivos-aula/arquivos_csv/'\n",
    "\n",
    "# Leitura do arquivo CSV\n",
    "df_clientes = spark.read.format('csv') \\\n",
    "    .option('header', 'true') \\\n",
    "    .option('inferSchema', 'true') \\\n",
    "    .load(file_path)\n",
    "\n",
    "# Exibe o DataFrame\n",
    "display(df_clientes)\n",
    "\n",
    "colunas = [\"first_name\", \"email\", \"state\", \"country\"] # Seta apenas as colunas informadas\n",
    "display(df_clientes.select(colunas)) # Mostra as colunas setadas\n",
    "\n",
    "colunas = [\"first_name\", \"email\", \"state\", \"country\"] # Seta apenas as colunas informadas\n",
    "dfColunasFiltradas = df.select(colunas) # Salva as colunas num novo DF chamado ColunasFiltradas\n",
    "\n",
    "dfColunasFiltradas.show() # Mostra o novo DF com as colunas setadas (filtradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e128ab2",
   "metadata": {},
   "source": [
    "# Caso deseje também poderia subscrever o DF\n",
    "\n",
    "dfColunasFiltradas = df.select('first_name', 'cell_phone', 'state') # Sobrescreve \"atualiza\" o DF chamado ColunasFiltradas com as novas colunas setadas (selecionadas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4e6f5",
   "metadata": {},
   "source": [
    "### # Criando um SCHEMA para salvar o DF em uma tabela física\n",
    "\n",
    "# 1º Alterar a linguagem para SQL.\n",
    "# 2º Rodar: CREATE SCHEMA WORKSPACE.nomeDoSchema Ex: CREATE SCHEMA WORKSPACE.TabelasSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15adaf",
   "metadata": {},
   "source": [
    "### # Salva o Data Frame em uma tabela física. Por padrão o Databricks salva no Workspace/default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0368868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho do arquivo\n",
    "file_path = 'dbfs:/Volumes/workspace/default/arquivos-aula/arquivos_csv/'\n",
    "\n",
    "# Leitura do arquivo CSV\n",
    "df_clientes = spark.read.format('csv') \\\n",
    "    .option('header', 'true') \\\n",
    "    .option('inferSchema', 'true') \\\n",
    "    .load(file_path)\n",
    "\n",
    "# Salva o Data Frame como uma tabela física\n",
    "\n",
    "df_clientes.write.mode('overwrite').saveAsTable('clientes') \n",
    "# Para alterar o local onde a tabela 'clientes' será salva, é só incluir o nome do schema antes do nome da tabela. Ex: .saveAsTable('TabelasSQL.clientes') do exemplo acima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fceeef",
   "metadata": {},
   "source": [
    "# Exibir o Data Frame 'em SQL'\n",
    "# SELECT * FROM default.clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee36860",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Caminho do arquivo\n",
    "file_path = 'dbfs:/Volumes/workspace/default/arquivos-aula/arquivos_csv/Clientes.csv'\n",
    "\n",
    "# Leitura do arquivo CSV'\n",
    "df_clientes = spark.read.format('csv') \\\n",
    "    .option('header', 'true') \\\n",
    "    .option('inferSchema', 'true') \\\n",
    "    .load(file_path)\n",
    "\n",
    "# Salva o Data Frame como tabela física\n",
    "df_clientes.write.mode('overwrite').saveAsTable('tabelas_sql.clientes') # 'tabelas_sql' é o nome dado ao Schema na etapa acima e 'clientes' é o nome da tabela.\n",
    "\n",
    "# Código para excluir o SCHEMA caso em algum momento necessite:\n",
    "\n",
    "# DROP SCHEMA WORKSPACE.nomedoschema CASCADE (ex: drop schema tabelas_sql cascade - Não usar cascade em produção.)\n",
    "\n",
    "# Código para excluir a tabela caso em algum momento necessite:\n",
    "\n",
    "# DROP TABLE WORKSPACE.nomedoschema.nomedatabela (ex: drop table tabelas_sql.clientes)\n",
    "\n",
    "df_clientes.show(5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
