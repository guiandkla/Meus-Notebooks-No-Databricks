{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0530676",
   "metadata": {},
   "source": [
    "### # Salvando o Data Frame em diferentes formatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0938f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar quais pastas existem dentro do diretório\n",
    "display(dbutils.fs.ls('/Volumes/workspace/default/arquivos-aula'))\n",
    "\n",
    "# Criar uma nova pasta\n",
    "dbutils.fs.mkdirs('/Volumes/workspace/default/arquivos-aula/DiferentesFormatos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cf584f",
   "metadata": {},
   "source": [
    "### # Termos técnicos para manipulação de pastas e arquivos\n",
    "\n",
    "# WRITE = Escrever/Gravar\n",
    "# OVERWRITE = Sobrescreve/Substitui arquivo que já existe\n",
    "# APPEND = Mantém o que já existe e adciona o novo conteúdo no final\n",
    "# IGNORE = Salva somente se o local de destino não existir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32e3f0",
   "metadata": {},
   "source": [
    "### # Selecionar o SCHEMA (db_bikes), fazer uma consulta na tabela para depois criar o Data Frame e então salvá-lo em outros formatos como por exemplo PARQUET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea678b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE db_bikes;\n",
    "-- Consulta de contratos de clientes.\n",
    "\n",
    "SELECT customer_id as Id,\n",
    "first_name as Nome,\n",
    "phone as Telefone,\n",
    "email as Email\n",
    "FROM clientes WHERE first_name like \"G%\"; -- Filtra os nomes que começam com a letra G."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e2df90",
   "metadata": {},
   "source": [
    "### # Utilizando o Spark para ler Query SQL (apenas ler, ainda não salva em um Data Frame):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfce39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT\n",
    "customer_id as Id,\n",
    "first_name as Nome,\n",
    "phone as Telefone,\n",
    "email as Email\n",
    "FROM clientes\n",
    "WHERE first_name like \"G%\" -- Filtra os nomes que começam com a letra G.\n",
    "\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bab762",
   "metadata": {},
   "source": [
    "### # Salvando a Query em um Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00384688",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSQL = spark.sql(\"\"\"     -- Dá um nome para o Data Frame (neste exemplo é dfSQL), e remove o .show() que servia para visualizar os dados selecionados.\n",
    "\n",
    "SELECT\n",
    "customer_id as Id,\n",
    "first_name as Nome,\n",
    "phone as Telefone,\n",
    "email as Email\n",
    "FROM clientes\n",
    "WHERE first_name like \"G%\"\n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### # Visualizando o DF criado\n",
    "\n",
    "display(dfSQL)\n",
    "\n",
    "### # Salvando o Data Frame em formato PARQUET\n",
    "\n",
    "dfSQL.write.mode(\"overwrite\").parquet(\"/Volumes/workspace/default/arquivos-aula/DiferentesFormatos/formatoParquet\") # Escreve o Data Frame no formato Parquet em que WRITE é o modo de escrita, e OVERWRITE é o modo de sobrescrita.\n",
    "\n",
    "### # Salvando Data Frame em formato CSV e JSON\n",
    "\n",
    "dfSQL.write.option(\"delimiter\", \",\").mode(\"overwrite\").csv(\"/Volumes/workspace/default/arquivos-aula/DiferentesFormatos/formatoCSV\") # Formato CSV\n",
    "dfSQL.write.mode(\"overwrite\").json(\"/Volumes/workspace/default/arquivos-aula/DiferentesFormatos/formatoJSON\") # Formato JSON\n",
    "\n",
    "display(dbutils.fs.ls('/Volumes/workspace/default/arquivos-aula/DiferentesFormatos')) # Verifica se os arquivos foram criados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792fc681",
   "metadata": {},
   "outputs": [],
   "source": [
    "### # Organizar o código \"quebrando em partes\" com \\\n",
    "\n",
    "# Modo de escrita com \\\n",
    "    \n",
    "dfSQL.write\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .csv(\"/Volumes/workspace/default/arquivos-aula/DiferentesFormatos/formatoCSV\")\n",
    "\n",
    "# O resultado será o mesmo da forma de criar o Data Frame acima, porém é uma forma mais elegante de escrever o código e mais fácil de alterar alguma opção ou caminho caso seja necessário."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b79fc8",
   "metadata": {},
   "source": [
    "### # Ler o arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o arquivo CSV\n",
    "caminho_csv = \"/Volumes/workspace/default/arquivos-aula/DiferentesFormatos/formatoCSV\"\n",
    "\n",
    "# Ler o arquivo CSV\n",
    "df_csv = spark.read.csv(caminho_csv, header=False, inferSchema=True)\n",
    "\n",
    "# Mostrar o conteúdo do DataFrame\n",
    "display(df_csv)\n",
    "\n",
    "### # Alterar (renomear) as colunas da tabela\n",
    "\n",
    "df_csv = df_csv.withColumnRenamed(\"_c0\", \"Id\")\\\n",
    "               .withColumnRenamed(\"_c1\", \"Nome\")\\\n",
    "               .withColumnRenamed(\"_c2\", \"Telefone\")\\\n",
    "               .withColumnRenamed(\"_c3\", \"E-mail\")\n",
    "\n",
    "display(df_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93e794",
   "metadata": {},
   "source": [
    "### # Ler o arquivo JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f49b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o arquivo JSON\n",
    "caminho_json = \"/Volumes/workspace/default/arquivos-aula/DiferentesFormatos/formatoJSON\"\n",
    "\n",
    "# Ler o arquivo JSON salvo no Data Frame\n",
    "df_json = spark.read.json(caminho_json)\n",
    "\n",
    "# Mostrar o conteúdo do Data Frame)\n",
    "display(df_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc329be",
   "metadata": {},
   "source": [
    "### # Ler arquivo no formato PARQUET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o arquivo PARQUET\n",
    "caminho_parquet = \"/Volumes/workspace/default/arquivos-aula/DiferentesFormatos/formatoParquet\"\n",
    "\n",
    "# Ler o arquivo PARQUET salvo no Data Frame\n",
    "df_parquet = spark.read.parquet(caminho_parquet)\n",
    "\n",
    "# Mostrar o conteúdo do Data Frame)\n",
    "display(df_parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab18ca85",
   "metadata": {},
   "source": [
    "### # Cria um novo DF para salvar dados particionados (apenas partes de uma tabela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um novo Data Frame da tabela clientes\n",
    "\n",
    "novoDf = spark.sql('select * from db_bikes.clientes')\n",
    "display(novoDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94dcff0",
   "metadata": {},
   "source": [
    "### # Ler o novo PARQUET particionado em forma de tabela (no exemplo abaixo somente os dados do estado de NY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271cf9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o arquivo PARQUET\n",
    "novo_parquet = \"dbfs:/Volumes/workspace/default/arquivos-aula/DiferentesFormatos/particionado_formatoParquet/state=NY/\" # Mostra somente do estado de NY\n",
    "\n",
    "# Se alterar para CA ou TX ao invés de NY mostrará somente os que são dos estados selecionados.\n",
    "# Se remover o /state=NY/ mostrará todos os arquivos do Data Frame normalmente.\n",
    "\n",
    "# Ler o arquivo PARQUET salvo no Data Frame\n",
    "df_Ny = spark.read.parquet(novo_parquet)\n",
    "\n",
    "# Mostrar o conteúdo do Data Frame)\n",
    "display(df_Ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c821c77f",
   "metadata": {},
   "source": [
    "### # Altera o nome das colunas da tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c1b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Ny = df_Ny.withColumnRenamed(\"customer_id\", \"Id\")\\\n",
    "             .withColumnRenamed(\"first_name\", \"Nome\")\\\n",
    "             .withColumnRenamed(\"last_name\", \"Sobrenome\")\\\n",
    "             .withColumnRenamed(\"phone\", \"Telefone\")\\\n",
    "             .withColumnRenamed(\"email\", \"Email\")\\\n",
    "             .withColumnRenamed(\"street\", \"Rua\")\\\n",
    "             .withColumnRenamed(\"city\", \"Cidade\")\\\n",
    "             .withColumnRenamed(\"zip_code\", \"CEP\")\n",
    "\n",
    "             # \"nomeDaColunaVELHA\", \"nomeDaColunaNOVA\"\n",
    "\n",
    "display(df_Ny)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
